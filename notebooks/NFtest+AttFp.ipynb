{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "BASEDIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(BASEDIR)\n",
    "\n",
    "from copy import deepcopy\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from src.model.attentivefp import attentivefp\n",
    "from src.utils.mol.attfp_graph import MoleculeDataset, collate_fn\n",
    "from src.config.attentivefp import attentivefpArgs\n",
    "from src.pipeline.ensemble import training_ensemble_models\n",
    "from src.utils.basic.logger import Writer\n",
    "from src.utils.model.metrics import accuracy, roc_auc_score, prc_auc\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)\n",
    "\n",
    "target_name = \"NFtest\"\n",
    "gpu_num     = 0\n",
    "\n",
    "h_p = {'hidden_size': 300,\n",
    "       'p_dropout'  : 0.1,\n",
    "       'dropout'    : 0.1,\n",
    "       'T'          : 2,\n",
    "       'radius'     : 3,\n",
    "       'fingerprint_dim': 150,\n",
    "       'ffn_num_layers': 3,\n",
    "       'init_lr' : 0.001}\n",
    "\n",
    "INT_KEYS = ['hidden_size', 'radius', 'T', 'ffn_num_layers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = os.path.join(BASEDIR, \"results\", target_name, 'AttFp')\n",
    "DATADIR = os.path.join(BASEDIR, \"data\", target_name)\n",
    "n = 0\n",
    "logger = Writer(os.path.join(SAVEDIR, \"history.log\"))\n",
    "def func(hyperparams):\n",
    "    logger(\" \")\n",
    "    logger(\" \")\n",
    "\n",
    "    global n\n",
    "    n = n+1\n",
    "    logger(f\"ROUND {n}\")\n",
    "\n",
    "    BASESAVEDIR = os.path.join(SAVEDIR, f\"ROUND_{n}\")\n",
    "\n",
    "    for key in INT_KEYS:\n",
    "        hyperparams[key] = int(hyperparams[key])\n",
    "\n",
    "    config = attentivefpArgs().parse_args([], known_only=True)\n",
    "    hyper_args = deepcopy(config)\n",
    "    folder_name = '_'.join(f'{key}_{value}' for key, value in hyperparams.items())\n",
    "    save_dir = os.path.join(BASESAVEDIR, folder_name)\n",
    "\n",
    "    for key, value in hyperparams.items():\n",
    "        setattr(hyper_args, key, value)\n",
    "\n",
    "    setattr(hyper_args, \"dataset_type\", \"classification\")\n",
    "    setattr(hyper_args, 'metric', \"roc-auc\")\n",
    "    setattr(hyper_args, \"extra_metrics\", [\"prc-auc\", \"accuracy\"])\n",
    "    setattr(hyper_args, \"ffn_hidden_size\", hyper_args.hidden_size)\n",
    "    setattr(hyper_args, \"early_stopping_num\", 10)\n",
    "    setattr(hyper_args, \"gpu\", gpu_num)\n",
    "    setattr(hyper_args, \"log_frequency\", 20)\n",
    "    setattr(hyper_args, \"batch_size\", 128)\n",
    "    setattr(hyper_args, \"at_least_epoch\", 10)\n",
    "    print(hyper_args)\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        train_dataset = MoleculeDataset(os.path.join(DATADIR, \"NFtrain.csv\"))\n",
    "        valid_dataset = MoleculeDataset(os.path.join(DATADIR, \"NFvalid.csv\"))\n",
    "        test_dataset  = MoleculeDataset(os.path.join(DATADIR, \"NFtest.csv\"))\n",
    "\n",
    "        train_dataloader = GraphDataLoader(dataset=train_dataset, collate_fn=collate_fn, batch_size=512, drop_last=False, shuffle=True)\n",
    "        train_dataloader.smiles = [[s] for s in train_dataset.smiles_list]\n",
    "        valid_dataloader = GraphDataLoader(dataset=valid_dataset, collate_fn=collate_fn, batch_size=512, drop_last=False, shuffle=False)\n",
    "        valid_dataloader.smiles = [[s] for s in valid_dataset.smiles_list]\n",
    "        test_dataloader  = GraphDataLoader(dataset=test_dataset,  collate_fn=collate_fn, batch_size=512, drop_last=False, shuffle=False)\n",
    "        test_dataloader.smiles  = [[s] for s in test_dataset.smiles_list]\n",
    "\n",
    "        training_ensemble_models(os.path.join(save_dir, f\"fold_{i}\"),\n",
    "                                 attentivefp,\n",
    "                                 hyper_args,\n",
    "                                 train_dataloader,\n",
    "                                 valid_dataloader=valid_dataloader,\n",
    "                                 test_dataloader=test_dataloader,\n",
    "                                 ensemble_num=1)\n",
    "        \n",
    "        test_prediction = []\n",
    "        \n",
    "        valid_ROC = []\n",
    "        valid_PRC = []\n",
    "        valid_ACC = []\n",
    "        \n",
    "        test_ROC  = []\n",
    "        test_PRC  = []\n",
    "        test_ACC  = []\n",
    "\n",
    "    for i in range(5):\n",
    "    \n",
    "        temp_dir = os.path.join(save_dir, f\"fold_{i}\", \"model_0\")\n",
    "        test_prediction.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction.csv\"))[\"property_pred\"].to_numpy())\n",
    "        valid_ROC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"roc-auc\"].iloc[0])\n",
    "        valid_PRC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"prc-auc\"].iloc[0])\n",
    "        valid_ACC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"accuracy\"].iloc[0])\n",
    "        \n",
    "        test_ROC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"roc-auc\"].iloc[0])\n",
    "        test_PRC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"prc-auc\"].iloc[0])\n",
    "        test_ACC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"accuracy\"].iloc[0])\n",
    "        \n",
    "        test_label = pd.read_csv(os.path.join(temp_dir, \"test_prediction.csv\"))[\"property_label\"].to_numpy()        \n",
    "\n",
    "    logger(f'ROUND {n} Valid ROC-AUC {np.mean(valid_ROC)} +/- {np.std(valid_ROC)}')\n",
    "    logger(f'ROUND {n} Valid PRC-AUC {np.mean(valid_PRC)} +/- {np.std(valid_PRC)}')\n",
    "    logger(f'ROUND {n} Valid ACC     {np.mean(valid_ACC)} +/- {np.std(valid_ACC)}')\n",
    "    logger(' ')\n",
    "    logger(f'ROUND {n} Test ROC-AUC {np.mean(test_ROC)} +/- {np.std(test_ROC)}')\n",
    "    logger(f'ROUND {n} Test PRC-AUC {np.mean(test_PRC)} +/- {np.std(test_PRC)}')\n",
    "    logger(f'ROUND {n} Test ACC     {np.mean(test_ACC)} +/- {np.std(test_ACC)}')\n",
    "    logger(' ')\n",
    "    logger(f'ROUND {n} Ensemble Test ROC-AUC {roc_auc_score(test_label, np.mean(test_prediction, axis=0))}')\n",
    "    logger(f'ROUND {n} Ensemble Test PRC-AUC {prc_auc(test_label, np.mean(test_prediction, axis=0))}')\n",
    "    logger(f'ROUND {n} Ensemble Test ACC {accuracy(test_label, np.mean(test_prediction, axis=0))}')\n",
    "    logger(' ')\n",
    "\n",
    "    return -np.mean(valid_ROC)\n",
    "\n",
    "func(h_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
