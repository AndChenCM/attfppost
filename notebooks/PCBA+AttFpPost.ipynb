{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "BASEDIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(BASEDIR)\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from src.model.attentivefp_postnet import attentivefpPostNet\n",
    "from src.utils.mol.attfp_graph import MoleculeDataset, MoleculeDataLoader\n",
    "from src.config.attentivefp_postnet import attentivefpPostNetArgs\n",
    "from src.pipeline.ensemble import training_ensemble_models\n",
    "from src.utils.basic.logger import Writer\n",
    "from src.utils.model.metrics import accuracy, roc_auc_score, prc_auc, EF1, MCC, bedroc_score\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)\n",
    "\n",
    "target_list = ['MAPK1', 'FEN1', 'PKM2', 'GBA', 'ALDH1', 'VDR', 'KAT2A']\n",
    "gpu_num     = 0\n",
    "\n",
    "INT_KEYS = ['hidden_size', 'ffn_num_layers', 'n_density', 'latent_dim']\n",
    "\n",
    "# using default hyperparameter\n",
    "\n",
    "h_p = {'hidden_size': 300,\n",
    "    'p_dropout'  : 0.1,\n",
    "    'dropout'    : 0.1,\n",
    "    'T'          : 2,\n",
    "    'radius'     : 3,\n",
    "    'ffn_num_layers': 3,\n",
    "    'init_lr' : 0.001,\n",
    "    'latent_dim': 6,\n",
    "    'n_density': 6,\n",
    "    'density_type': 'iaf_flow'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_name in target_list:\n",
    "    \n",
    "    SAVEDIR = os.path.join(BASEDIR, \"results\", \"PCBA\", target_name, 'AttFpPost')\n",
    "    DATADIR = os.path.join(BASEDIR, \"data\", \"PCBA\", target_name)\n",
    "    n = 0\n",
    "    logger = Writer(os.path.join(SAVEDIR, \"history.log\"))\n",
    "    def func(hyperparams):\n",
    "        logger(\" \")\n",
    "        logger(\" \")\n",
    "\n",
    "        global n\n",
    "        while n < 5:\n",
    "            n = n+1\n",
    "            logger(f\"ROUND {n}\")\n",
    "\n",
    "            BASESAVEDIR = os.path.join(SAVEDIR, f\"ROUND_{n}\")\n",
    "            \n",
    "            for key in INT_KEYS:\n",
    "                hyperparams[key] = int(hyperparams[key])\n",
    "\n",
    "            config = attentivefpPostNetArgs().parse_args([], known_only=True)\n",
    "            hyper_args = deepcopy(config)\n",
    "\n",
    "            save_dir = BASESAVEDIR\n",
    "            \n",
    "            for key, value in hyperparams.items():\n",
    "                setattr(hyper_args, key, value)\n",
    "\n",
    "            setattr(hyper_args, \"dataset_type\", \"classification\")\n",
    "            setattr(hyper_args, \"latent_dim\", int(hyper_args.latent_dim))\n",
    "            setattr(hyper_args, 'metric', \"BEDROC\")\n",
    "            setattr(hyper_args, \"extra_metrics\", [\"roc-auc\", \"MCC\", \"prc-auc\", \"accuracy\", \"EF1\"])\n",
    "            setattr(hyper_args, \"ffn_hidden_size\", hyper_args.hidden_size)\n",
    "            setattr(hyper_args, \"early_stopping_num\", 50)\n",
    "            setattr(hyper_args, \"gpu\", gpu_num)\n",
    "            setattr(hyper_args, \"log_frequency\", 300)\n",
    "            setattr(hyper_args, \"batch_size\", 1024)\n",
    "            print(hyper_args)\n",
    "\n",
    "            for i in range(5):\n",
    "\n",
    "                train_dataset = MoleculeDataset(os.path.join(DATADIR, f\"{target_name}_train_{i}.csv\"))\n",
    "                valid_dataset = MoleculeDataset(os.path.join(DATADIR, f\"{target_name}_valid_{i}.csv\"))\n",
    "                test_dataset = MoleculeDataset(os.path.join(DATADIR, f\"{target_name}_test.csv\"))\n",
    "\n",
    "                train_dataloader = MoleculeDataLoader(dataset=train_dataset, batch_size=hyper_args.batch_size, shuffle=True , class_balance=True)\n",
    "                train_dataloader.smiles = [[s] for s in train_dataset.smiles_list]\n",
    "                valid_dataloader = MoleculeDataLoader(dataset=valid_dataset, batch_size=hyper_args.batch_size, shuffle=False)\n",
    "                valid_dataloader.smiles = [[s] for s in valid_dataset.smiles_list]\n",
    "                test_dataloader  = MoleculeDataLoader(dataset=test_dataset,  batch_size=hyper_args.batch_size, shuffle=False)\n",
    "                test_dataloader.smiles = [[s] for s in test_dataset.smiles_list]\n",
    "\n",
    "                train_targets = []\n",
    "                for _, t in train_dataset:\n",
    "                    train_targets.append(t)\n",
    "\n",
    "                N = torch.tensor([len(train_targets) - np.sum(train_targets).astype(np.int64),\n",
    "                                np.sum(train_targets).astype(np.int64)], dtype=torch.float64)\n",
    "\n",
    "                setattr(hyper_args, \"N\", N)\n",
    "                \n",
    "                training_ensemble_models(os.path.join(save_dir, f\"fold_{i}\"),\n",
    "                                        attentivefpPostNet,\n",
    "                                        hyper_args,\n",
    "                                        train_dataloader,\n",
    "                                        valid_dataloader=valid_dataloader,\n",
    "                                        test_dataloader=test_dataloader,\n",
    "                                        ensemble_num=1)\n",
    "                \n",
    "            test_prediction = []\n",
    "            valid_ROC = []\n",
    "            valid_PRC = []\n",
    "            valid_ACC = []\n",
    "            valid_MCC = []\n",
    "            valid_EF1  = []\n",
    "            valid_BEDROC= []\n",
    "\n",
    "            test_ROC  = []\n",
    "            test_PRC  = []\n",
    "            test_ACC  = []\n",
    "            test_MCC  = []\n",
    "            test_EF1   = []\n",
    "            test_BEDROC = []\n",
    "\n",
    "            for i in range(5):\n",
    "                temp_dir = os.path.join(save_dir, f\"fold_{i}\", \"model_0\")\n",
    "                test_prediction.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction.csv\"))[\"property_pred\"].to_numpy())\n",
    "                valid_ROC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"roc-auc\"].iloc[0])\n",
    "                valid_PRC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"prc-auc\"].iloc[0])\n",
    "                valid_ACC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"accuracy\"].iloc[0])\n",
    "                valid_MCC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"MCC\"].iloc[0])\n",
    "                valid_EF1.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"EF1\"].iloc[0])\n",
    "                valid_BEDROC.append(pd.read_csv(os.path.join(temp_dir, \"valid_prediction_performance.csv\"))[\"BEDROC\"].iloc[0])\n",
    "\n",
    "                test_ROC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"roc-auc\"].iloc[0])\n",
    "                test_PRC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"prc-auc\"].iloc[0])\n",
    "                test_ACC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"accuracy\"].iloc[0])\n",
    "                test_MCC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"MCC\"].iloc[0])\n",
    "                test_EF1.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"EF1\"].iloc[0])\n",
    "                test_BEDROC.append(pd.read_csv(os.path.join(temp_dir, \"test_prediction_performance.csv\"))[\"BEDROC\"].iloc[0])\n",
    "\n",
    "                test_label = pd.read_csv(os.path.join(temp_dir, \"test_prediction.csv\"))[\"property_label\"].to_numpy()\n",
    "\n",
    "            logger(f'ROUND {n} Valid ROC-AUC {np.mean(valid_ROC)} +/- {np.std(valid_ROC)}')\n",
    "            logger(f'ROUND {n} Valid PRC-AUC {np.mean(valid_PRC)} +/- {np.std(valid_PRC)}')\n",
    "            logger(f'ROUND {n} Valid ACC     {np.mean(valid_ACC)} +/- {np.std(valid_ACC)}')\n",
    "            logger(f'ROUND {n} Valid MCC     {np.mean(valid_MCC)} +/- {np.std(valid_MCC)}')\n",
    "            logger(f'ROUND {n} Valid EF1     {np.mean(valid_EF1)} +/- {np.std(valid_EF1)}')\n",
    "            logger(f'ROUND {n} Valid BEDROC  {np.mean(valid_BEDROC)} +/- {np.std(valid_BEDROC)}')\n",
    "\n",
    "            logger(' ')\n",
    "            logger(f'ROUND {n} Test ROC-AUC {np.mean(test_ROC)} +/- {np.std(test_ROC)}')\n",
    "            logger(f'ROUND {n} Test PRC-AUC {np.mean(test_PRC)} +/- {np.std(test_PRC)}')\n",
    "            logger(f'ROUND {n} Test ACC     {np.mean(test_ACC)} +/- {np.std(test_ACC)}')\n",
    "            logger(f'ROUND {n} Test MCC     {np.mean(test_MCC)} +/- {np.std(test_MCC)}')\n",
    "            logger(f'ROUND {n} Test EF1     {np.mean(test_EF1)}  +/- {np.std(test_EF1)}')\n",
    "            logger(f'ROUND {n} Test BEDROC  {np.mean(test_BEDROC)}  +/- {np.std(test_BEDROC)}')\n",
    "\n",
    "            logger(' ')\n",
    "            logger(f'ROUND {n} Ensemble Test ROC-AUC {roc_auc_score(test_label, np.mean(test_prediction, axis=0))}')\n",
    "            logger(f'ROUND {n} Ensemble Test PRC-AUC {prc_auc(test_label, np.mean(test_prediction, axis=0))}')\n",
    "            logger(f'ROUND {n} Ensemble Test ACC {accuracy(test_label, np.mean(test_prediction, axis=0))}')\n",
    "            logger(f'ROUND {n} Ensemble Test MCC {MCC(test_label, np.mean(test_prediction, axis=0))}')\n",
    "            logger(f'ROUND {n} Ensemble Test EF1 {EF1(test_label, np.mean(test_prediction, axis=0))}')\n",
    "            logger(f'ROUND {n} Ensemble Test BEDROC {bedroc_score(test_label, np.mean(test_prediction, axis=0))}')\n",
    "            logger(' ')\n",
    "\n",
    "        return -np.mean(valid_ROC)\n",
    "    \n",
    "    func(h_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
